{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d0df0250-eb83-4221-8c6a-c068cf438e10",
   "metadata": {},
   "source": [
    "# Module 4 - Reducing unfairness in learning algorithm applications \n",
    "\n",
    "\n",
    "### Assignment overview\n",
    "\n",
    "In this assignment, you are tasked to create a classifer to predict the estimated income of individuals in the [Kaggle Adult Income Dataset](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset). This dataset is known to be biased towards certain groups. You will try some strategies to create a more fair classifier.\n",
    "\n",
    "For this assignment, it is possible to work in **groups of up to 2 students**. Read the instructions carefully, as they may assign tasks to specific students.\n",
    "\n",
    "### Group members\n",
    "Leave blanks if group has less than 2 members:\n",
    "- Student 1:\n",
    "- Student 2:\n",
    "\n",
    "\n",
    "### Learning Goals:\n",
    "\n",
    "After completing this week's lecture and tutorial work, you will be able to:\n",
    "1. Discuss the consequences of erroneous (biased) data on the training of learning algorithms and how it impacts its end users  \n",
    "2. Discuss potential ethical implications in errors in feature selection, model selection \n",
    "3. Describe strategies for reducing algorithmic bias \n",
    "4. Apply strategies to reduce unfairness in a predictive model trained on an unbalanced dataset \n",
    "5. Describe advantages and limitations of the strategies used to reduce unfairness in predictive models"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0af265b-c6aa-497a-8fb5-d14afeba29b7",
   "metadata": {},
   "source": [
    "### Libraries\n",
    "\n",
    "Here are some libraries you will need for this assignment. `imblearn` and `aif360` are new ones, you can install it by running the cell below. Comment out this line after one execution:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c7fa076a-9816-406e-970d-03c0386acc5a",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# !pip install imblearn\n",
    "# !pip install aif360"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f8025138",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.preprocessing import OneHotEncoder, LabelEncoder\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.compose import ColumnTransformer, make_column_transformer\n",
    "from sklearn.pipeline import Pipeline, make_pipeline\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler\n",
    "from imblearn.over_sampling import SMOTENC\n",
    "import matplotlib.pyplot as plt\n",
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ef61a1a6-53d6-411e-ae78-ce97137f07f3",
   "metadata": {},
   "source": [
    "### Dataset\n",
    "\n",
    "The dataset you will use for this assignment is the [Kaggle Adult Income Dataset](https://www.kaggle.com/datasets/wenruliu/adult-income-dataset). You may visit the source page for more information about this dataset.\n",
    "\n",
    "The dataset includes 15 columns: 14 of them are demographics and other features to describe a person, and one (the target variable), is their income. The income variable is binary and has the two possible values `<=50K` or `>50K`.\n",
    "\n",
    "Let's start by importing the dataset and taking a look (you are free to add other lines if you want more details):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1379b33e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"adult.csv\")\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e40dac5-6aae-448e-aa57-fb9bdc083f59",
   "metadata": {},
   "source": [
    "Unfortunately, this dataset is notoriously biased in the association between income and other demographic information, such as race and gender. Let's see how.\n",
    "\n",
    "#### Question 1 \n",
    "Create the following 3 bar charts:\n",
    "- A global bar chart of the target variable\n",
    "- A bar chart of the target variable divided by gender\n",
    "- A bar chart of the target variable divided by race\n",
    "\n",
    "Comment on the results. Is the target variable balanced? Is the target variable balanced across protected groups?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e193708-7620-4b89-8b8b-6aeceb58a414",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a0c9e5-1224-490f-be94-b6367dd662d5",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9070e9db-576b-48fc-ab34-62a151ea6f13",
   "metadata": {},
   "source": [
    "### A biased classifier\n",
    "\n",
    "We can expect that a classifier trained on this kind of data will show some problematic behaviors when assigning an individual to a predicted income level. Let's visualize this using a random forest classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f12f218",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 1\n",
    "# Run this cell create training and test sets\n",
    "train_df, test_df = train_test_split(df, test_size=0.3, random_state=123)\n",
    "\n",
    "X_train, y_train = (\n",
    "    train_df.drop(columns=[\"income\"]),\n",
    "    train_df[\"income\"],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_df.drop(columns=[\"income\"]),\n",
    "    test_df[\"income\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ddc85e2",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 2\n",
    "# Run this cell to do the necessary dataset preprocessing (encoding of categorical features).\n",
    "# Note that, since we are using a tree based classifier, we don't need to scale the \n",
    "# numerical features.\n",
    "\n",
    "categorical_feats = [\"workclass\",\n",
    "                     \"education\",\n",
    "                     \"marital-status\",\n",
    "                     \"occupation\",\n",
    "                     \"relationship\",\n",
    "                     \"race\",\n",
    "                     \"gender\",\n",
    "                     \"native-country\",\n",
    "                     ]  # Apply one-hot encoding\n",
    "passthrough_feats = [\"age\",\n",
    "                \"fnlwgt\",\n",
    "                \"educational-num\",\n",
    "                \"capital-gain\",\n",
    "                \"capital-loss\",\n",
    "                \"hours-per-week\"\n",
    "                ]  # Numerical - no need to scale\n",
    "target = \"income\"\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(OneHotEncoder(handle_unknown=\"ignore\",drop=\"if_binary\")),\n",
    "        categorical_feats,\n",
    "    ),  # OHE on categorical features\n",
    "    (\"passthrough\", passthrough_feats)  # no transformations on numerical features\n",
    ")\n",
    "\n",
    "X_train_transformed = ct.fit_transform(X_train).toarray()\n",
    "\n",
    "column_names = list(\n",
    "    ct.named_transformers_[\"pipeline\"].get_feature_names_out(\n",
    "        categorical_feats\n",
    "    )\n",
    ") + passthrough_feats\n",
    "\n",
    "X_test_transformed = ct.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6237ca8b-545e-4887-89c9-5cfe24864cba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# You may use this lines to check the result\n",
    "# pd.DataFrame(X_train_transformed, columns=column_names)\n",
    "# pd.DataFrame(X_test_transformed, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12bddc7-e7b2-4c6c-8210-5f43f898cc2b",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# STEP 3\n",
    "# Run this cell to train a random forest classifer. The hyperparameters have been pre-selected\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "clf = RandomForestClassifier(random_state=0, max_depth = 19, n_estimators = 100).fit(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8e91002-096e-4778-8605-21b0befd709e",
   "metadata": {},
   "source": [
    "How good is this classifier? Let's check its accuracy, by running the cells below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77345674-789f-4d25-805c-3430ea53173f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.score(X_train_transformed, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df66983-645b-46b2-a550-bd742d06ccf6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "clf.score(X_test_transformed, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "de369cad-467e-4c4e-b71b-78a2cbcde10c",
   "metadata": {},
   "source": [
    "Finally, let's see what features are considered important by the classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "096b0ae6-5820-4ea5-b383-e145987781c5",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "feature_importances = clf.feature_importances_\n",
    "\n",
    "# Sort the feature importances from greatest to least using the sorted indices\n",
    "sorted_indices = feature_importances.argsort()[::-1]\n",
    "sorted_feature_names = ct.get_feature_names_out()[sorted_indices]\n",
    "sorted_importances = feature_importances[sorted_indices]\n",
    "\n",
    "# # Create a bar plot of the feature importances\n",
    "sns.set(rc={'figure.figsize':(11.7,30)})\n",
    "sns.barplot(x=sorted_importances, y=sorted_feature_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a789447e-1295-4bb1-a9fb-02b7b493f217",
   "metadata": {},
   "source": [
    "#### Question 2\n",
    "What are the most important features for this classifier? Do they include protected characteristics, such as race or gender?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36a8747b-984b-4a74-943b-8703d765da1a",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3c2fa0ae-55d9-4506-aa9a-929b1dc1d07c",
   "metadata": {},
   "source": [
    "#### Question 3\n",
    "\n",
    "From Assignment 3, we have learned that a classifier may perform well in terms of accuracy, but being unfair to protected groups in the dataset. Use what you have learned in Assignment 3 and **evaluate this classifier for fairness in treating the two gender groups included in this dataset.** In particular, do the following: \n",
    "\n",
    "- Compute the 6 fairness metrics and the Average Distance from the Reference on training and test sets. You may reuse portions of code you have included in Assignment 3.\n",
    "- Comment on the results, providing an interpretation for each computed metric; how different is the treatment of the two groups? Is one (or more) of the metrics particularly concerning?\n",
    "\n",
    "Here is a recap of the fairness metrics:\n",
    "1. *Predicted Positive Rate Disparity (PPRD)*, whether the numbers of positive predictions are on par across groups.\n",
    "2. *Predicted Positive Group Rate Disparity (PPGRD)*, whether the rates of positive predictions are on par across groups.\n",
    "3. *False Discovery Rate Disparity (FDRD)*, whether the ratios of false positives to predicted positives are on par across groups.\n",
    "4. *False Positive Rate Disparity (FPRD)*, whether the ratios of false positives to actual negatives are on par across groups.\n",
    "5. *False Omission Rate Disparity (FORD)*, whether the ratios of false negatives to predicted negatives are on par across groups.\n",
    "6. *False Negative Rate Disparity (FNRD)*, whether the ratios of false negatives to actual positives are on par across groups."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d0a47ad",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here (you may add more cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8387e2c-38ed-435a-adc8-6f53ae2ef831",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "39261b8e-d798-484a-97ce-9f159f9eb9ed",
   "metadata": {},
   "source": [
    "## Debiasing techniques: dropping protected characteristics\n",
    "\n",
    "A first idea to fix this issue could be dropping the protected characteristics from our dataset before training the classifier. Let's try this out and see if there is any improvement.\n",
    "\n",
    "#### Question 4\n",
    "1. Drop race, gender and native country from training and test set (we are focusing on gender but we will drop race and native country for good measure).\n",
    "2. Transform the cleaned dataset using one-hot encoding.\n",
    "3. Re-train the random forest classifier.\n",
    "4. Compare accuracy and fairness of this new classifier to the previous one. Do we see any improvement? How do you explain the changes you see (or lack thereof)? Note that, to compare fairness, you will need to have a way to identify the gender of each sample, even though you are not using this feature for classification.\n",
    "5. Create a new plot of the feature importance according to this classifier. Do you see any changes from the first one?\n",
    "\n",
    "**Hint:** steps 2, 3 and 5 can be completed by tweaking the starting code given at the beginning of this assignment. Ask a TA or instructor if you need help in doing that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0e11c463",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here (you may add more cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ec224e23-7be7-4bd2-b0c0-6e4cadfbaf92",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ea2ffcd0-4c5a-4bc1-840e-c372f54ac529",
   "metadata": {},
   "source": [
    "## Debiasing techniques: undersampling\n",
    "\n",
    "As you should have seen when exploring the dataset, the groups of males and females who make more or less than \\\\$50k are of very different sizes. This alone may have a significant impact on the way the classifier is trained, by teaching it that some groups are much more likely to make more than \\\\$50k than others.\n",
    "\n",
    "Let's try to fix this problem by creating a more balanced training set.\n",
    "\n",
    "#### Question 5\n",
    "1. Run the cell below to create a new training set by selecting a subset of samples from the original one, in which the groups of males and females who make more or less than \\\\$50k are of equal size. To use the maximum number of training samples possible, the size of each group should be equal to the size of the smallest of these groups in the original dataset. **What is the size of each group, and of the final training set?**\n",
    "2. Separate features from target, and transform the cleaned dataset using one-hot encoding. **Remeber to re-transform the test set accordingly!**\n",
    "3. Re-train the random forest classifier.\n",
    "4. Compare accuracy and fairness of this new classifier to the previous ones. Do we see any improvement? How do you explain the changes you see (or lack thereof)? Pay particular attention to the difference in results on the training and test set: can you explain these results?\n",
    "5. Create a new plot of the feature importance according to this classifier. Do you see any changes from the previous ones?\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdda565d-fb96-4642-9b79-79d3617e506f",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Check the distribution of gender and income\n",
    "gender_distribution = train_df['gender'].value_counts()\n",
    "income_distribution = train_df['income'].value_counts()\n",
    "\n",
    "# Create balanced subsets\n",
    "balanced_subsets = []\n",
    "smallest = train_df.shape[0]\n",
    "\n",
    "# Finding size of smallest subset by gender and income\n",
    "for gender_category in gender_distribution.index:\n",
    "    for income_category in income_distribution.index:\n",
    "        if train_df[(train_df['gender'] == gender_category) & (train_df['income'] == income_category)].shape[0] < smallest:\n",
    "            smallest = train_df[(train_df['gender'] == gender_category) & (train_df['income'] == income_category)].shape[0]\n",
    "    \n",
    "# Sampling subsets \n",
    "for gender_category in gender_distribution.index:\n",
    "    for income_category in income_distribution.index:\n",
    "        subset = train_df[(train_df['gender'] == gender_category) & (train_df['income'] == income_category)]\n",
    "        subset = subset.sample(smallest)  # Sample to match the minimum count\n",
    "        balanced_subsets.append(subset)\n",
    "        \n",
    "# Merge the balanced subsets to create the final balanced dataset\n",
    "balanced_df = pd.concat(balanced_subsets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76e83e04-ce97-40f4-805d-ee1af32eb679",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Your answer here (you may add more cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4e59f336-171a-48f8-8e3d-81a5c17938de",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "6c910ae2-813b-4fa6-9df9-6e5ce2c1c53e",
   "metadata": {},
   "source": [
    "## Debiasing techniques: oversampling (with SMOTE)\n",
    "\n",
    "Another way to create a more balanced training set, but without sacrificing training samples, is by *oversampling*, which means artificially increasing the size of the training set with \"fake\" samples. This can be achieved mainly in two ways:\n",
    "1. By resampling (replicating) samples from the original training set, or\n",
    "2. By introducing artificial *new* samples, similar enough to those included in the original training set\n",
    "\n",
    "The Synthetic Minority Oversampling Technique (SMOTE) seen in class falls in the second group. In this portion of the assignment, you will create a more balanced dataset using SMOTE (specifically [SMOTENC](https://imbalanced-learn.org/stable/references/generated/imblearn.over_sampling.SMOTENC.html), a version of SMOTE that allows working with categorical variables).\n",
    "\n",
    "#### Question 6\n",
    "1. Run the cell below to create a more balanced training set using SMOTE. Note that a large portion of code is replicated to guarantee that the correct data is used, and not one modified in previous cells. The actual rebalancing all happens in the last 2 lines.\n",
    "2. Explore the new training set, and provide the following information: what is the size of the new training set? Is the target variable balanced? How many samples are classified as >\\\\$50, and how many as <=\\\\$50k? Is the target variable balanced across protected groups, or at least more balanced than before? How many males and females are classified as >\\\\$50, and how many as <=\\\\$50k?\n",
    "3. Re-train the random forest classifier.\n",
    "4. Compare accuracy and fairness of this new classifier to the previous ones. Do we see any improvement? How do you explain the changes you see (or lack thereof)? Pay particular attention to the difference in results on the training and test set: can you explain these results?\n",
    "5. Create a new plot of the feature importance according to this classifier. Do you see any changes from the previous ones?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a070c468",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import SMOTENC\n",
    "\n",
    "X_train, y_train = (\n",
    "    train_df.drop(columns=[\"income\"]),\n",
    "    train_df[\"income\"],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_df.drop(columns=[\"income\"]),\n",
    "    test_df[\"income\"],\n",
    ")\n",
    "\n",
    "oversample = SMOTENC(categorical_features=categorical_feats, random_state=0)\n",
    "\n",
    "X_train_SMOTE, y_train_SMOTE = oversample.fit_resample(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "277dd314",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Transformation applied after oversampling\n",
    "\n",
    "categorical_feats = [\"workclass\",\n",
    "                     \"education\",\n",
    "                     \"marital-status\",\n",
    "                     \"occupation\",\n",
    "                     \"relationship\",\n",
    "                     \"race\",\n",
    "                     \"gender\",\n",
    "                     \"native-country\",\n",
    "                     ]  # Apply one-hot encoding\n",
    "passthrough_feats = [\"age\",\n",
    "                \"fnlwgt\",\n",
    "                \"educational-num\",\n",
    "                \"capital-gain\",\n",
    "                \"capital-loss\",\n",
    "                \"hours-per-week\"\n",
    "                ]  # Numerical - no need to scale\n",
    "target = \"income\"\n",
    "\n",
    "\n",
    "ctSMOTE = make_column_transformer(\n",
    "    (\n",
    "        OneHotEncoder(handle_unknown=\"ignore\",drop=\"if_binary\",sparse_output=False),\n",
    "        categorical_feats,\n",
    "    ),  # OHE on categorical features\n",
    "    (\"passthrough\", passthrough_feats)  # no transformations on numerical features\n",
    ")\n",
    "\n",
    "X_train_transformed = ctSMOTE.fit_transform(X_train_SMOTE)\n",
    "X_test_transformed = ctSMOTE.transform(X_test)\n",
    "\n",
    "# Column names, if needed\n",
    "column_names = list(\n",
    "    ctSMOTE.named_transformers_[\"onehotencoder\"].get_feature_names_out(\n",
    "        categorical_feats\n",
    "    )\n",
    ") + passthrough_feats\n",
    "\n",
    "# X_train_transformed and X_test_transformed can now be used to answer the questions above"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "946d9955",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Your answer here (you may add more cells)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b23488d7-6914-4548-a195-200a4832936d",
   "metadata": {},
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c9846f4d",
   "metadata": {},
   "source": [
    "## Equalized odd post processing\n",
    "\n",
    "An alternative to the methods seen so far (which may produce unsatisfactory results), is applying post-processing to the predictions of the classifier, so that they optimize equalized odds (whether the TPR and FPR are on par across groups).\n",
    "\n",
    "`aif360`, a popular open-source library dedicated to detecting and mitigating bias in machine learning models, includes [`EqOddsPostprocessing`](https://aif360.readthedocs.io/en/stable/modules/generated/aif360.algorithms.postprocessing.EqOddsPostprocessing.html), a function to performe equalized odds post-processing. The function is slightly more intricate to use than others you have used so far (typically from `sklearn`), so we will see together how to apply it on the test (you may try and replicate this on the training set for your own practice)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f562a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to reset training and test sets (and clear accidental prior changes)\n",
    "\n",
    "X_train, y_train = (\n",
    "    train_df.drop(columns=[\"income\"]),\n",
    "    train_df[\"income\"],\n",
    ")\n",
    "X_test, y_test = (\n",
    "    test_df.drop(columns=[\"income\"]),\n",
    "    test_df[\"income\"],\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "210651b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run this cell to do the necessary dataset preprocessing (encoding of categorical features).\n",
    "# Note that, since we are using a tree based classifier, we don't need to scale the \n",
    "# numerical features.\n",
    "\n",
    "categorical_feats = [\"workclass\",\n",
    "                     \"education\",\n",
    "                     \"marital-status\",\n",
    "                     \"occupation\",\n",
    "                     \"relationship\",\n",
    "                     \"race\",\n",
    "                     \"gender\",\n",
    "                     \"native-country\",\n",
    "                     ]  # Apply one-hot encoding\n",
    "passthrough_feats = [\"age\",\n",
    "                \"fnlwgt\",\n",
    "                \"educational-num\",\n",
    "                \"capital-gain\",\n",
    "                \"capital-loss\",\n",
    "                \"hours-per-week\"\n",
    "                ]  # Numerical - no need to scale\n",
    "target = \"income\"\n",
    "\n",
    "ct = make_column_transformer(\n",
    "    (\n",
    "        make_pipeline(OneHotEncoder(handle_unknown=\"ignore\",drop=\"if_binary\")),\n",
    "        categorical_feats,\n",
    "    ),  # OHE on categorical features\n",
    "    (\"passthrough\", passthrough_feats)  # no transformations on numerical features\n",
    ")\n",
    "\n",
    "X_train_transformed = ct.fit_transform(X_train).toarray()\n",
    "X_test_transformed = ct.transform(X_test).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "70a8815e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert numpy arrays to pandas dataframes\n",
    "\n",
    "column_names = list(\n",
    "    ct.named_transformers_[\"pipeline\"].get_feature_names_out(\n",
    "        categorical_feats\n",
    "    )\n",
    ") + passthrough_feats\n",
    "\n",
    "X_train_df = pd.DataFrame(X_train_transformed, columns=column_names)\n",
    "X_test_df = pd.DataFrame(X_test_transformed, columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d1894ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train RandomForestClassifier\n",
    "clf = RandomForestClassifier(random_state=0, max_depth = 19, n_estimators = 100).fit(X_train_df, y_train)\n",
    "\n",
    "# Get predictions for test set \n",
    "y_pred = clf.predict(X_test_df)\n",
    "\n",
    "# So far, all this is the same as the biased classifier we started with "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c838339d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert test data into a BinaryLabelDataset, necessary to work in aif360\n",
    "\n",
    "from aif360.datasets import BinaryLabelDataset\n",
    "\n",
    "X_test_df = X_test_df.reset_index(drop=True)\n",
    "y_test = y_test.reset_index(drop=True)\n",
    "\n",
    "y_binary = y_test.map({'>50K': 1, '<=50K': 0})  # Map categorical values to binary\n",
    "\n",
    "test_bld = BinaryLabelDataset(df=pd.concat([X_test_df, y_binary], axis=1),\n",
    "                              label_names=['income'],\n",
    "                              protected_attribute_names=['gender_Male'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59c7f1f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create another dataset with predicted labels for comparison\n",
    "test_pred_bld = test_bld.copy()\n",
    "\n",
    "# Convert to binary label (e.g., class 2 is positive, others are negative)\n",
    "y_pred_binary = np.where(y_pred == '>50K', 1, 0)\n",
    "\n",
    "test_pred_bld.labels = y_pred_binary.reshape(-1, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "063be1e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from aif360.algorithms.postprocessing import EqOddsPostprocessing\n",
    "\n",
    "# Initialize EqOddsPostprocessing\n",
    "eq_odds = EqOddsPostprocessing(unprivileged_groups=[{'gender_Male': 0}],\n",
    "                               privileged_groups=[{'gender_Male': 1}])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56d62114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fit the EqOddsPostprocessing model\n",
    "eq_odds = eq_odds.fit(test_bld, test_pred_bld)\n",
    "\n",
    "# Get new fair predictions\n",
    "fair_pred_bld = eq_odds.predict(test_pred_bld)\n",
    "\n",
    "# Convert predictions back to array\n",
    "fair_predictions = fair_pred_bld.labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d04670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "fair_predictions_cat = np.where(fair_predictions == 1, '>50K', '<=50K')\n",
    "fair_predictions_cat "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e7b83514",
   "metadata": {},
   "source": [
    "`fair_predictions_cat` now includes the post-processed predictions, after equalized odds postprocessing. \n",
    "\n",
    "#### Question 7\n",
    "\n",
    "Compute accuracy and fairness of this new predictions, and compare the results to the previous ones. Do we see any improvement? Is this technique more or less effective than the others tried before?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4da3ff92-6128-4a7d-afca-4ff69b28588b",
   "metadata": {},
   "source": [
    "## Final remarks\n",
    "\n",
    "#### Question 8\n",
    "\n",
    "Based on the results seen so far, provide an overall evaluation of our debiasing efforts. In particular, try answering the following questions:\n",
    "1. What do you think was the most successful technique? Which one was the least successful? \n",
    "2. If you found that bias still persists after attempting a debiasing strategy, what do you think is the reason? What could be done to fix this problem?\n",
    "\n",
    "(max 400 words)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "879b3b8a-bdc5-4f12-ab4b-f3999a1f07e4",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "cf90f251-74e8-44da-b2b0-253307e63136",
   "metadata": {},
   "source": [
    "# Final thoughts\n",
    "\n",
    "1) If you have completed this assignment in a group, please write a detailed description of how you divided the work and how you helped each other completing it:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3455b783-b858-4251-9a3c-b3829fc1a6c9",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "1659a333-01be-4c52-a54c-5ee16726ff9f",
   "metadata": {},
   "source": [
    "2) Have you used ChatGPT or a similar Large Language Model (LLM) to complete this homework? Please describe how you used the tool. We will never deduct points for using LLMs for completing homework assignments, but this helps us understand how you are using the tool and advise you in case we believe you are using it incorrectly."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9d3ab1fd-5925-4fc5-811b-da56d06247e7",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "361c40e0-bdca-45d1-87f9-901ae05db256",
   "metadata": {},
   "source": [
    "3) Have you struggled with some parts (or all) of this homework? Do you have pending questions you would like to ask? Write them down here!"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "527bb471-0278-45d3-8881-2810381e62b4",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:dsci430]",
   "language": "python",
   "name": "conda-env-dsci430-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
